---
title: "Features Comparison"
author: "Halil Bilgin"
date: "9 Nisan 2017"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(pander)

source('../autoload.R', chdir=T)
library(doMC)
registerDoMC(cores = 4)

repetitions <- 50
```

## Features Comparison

```r repetitions``` Different training-test split was used to measure performance. Table below represents confidence intervals of the different scores.

```{r mainSetup}
#bayesglm

algorithms <- loadClassifiers(c('lda'))

nonLinearFormula <- featureSelection$aic(c(featureSelection$fm(db,T)), scaledDb)



formulas <- c(
  featureSelection$aic(c(
        # Change + with * to get all interaction terms
       
        as.formula(
          gsub('\\+', '*', paste(nonLinearFormula, collapse=''))
        )    
                    ),
        starting = 'as.factor(gfrloss2) ~ 1',
        scaledDb, steps=100)
  #nonLinearFormula2
  )



print(lapply(formulas, function(fm) {
  paste(format(fm), collapse='')
}))


names(formulas) <- 1:length(formulas)

result <- data.frame(
  method=character(),
  Accuracy=numeric(),
  AccuracyNull=numeric(),
  Sensitivity=numeric(),
  Specificity=numeric(),
  Kappa=numeric()
)

```


```{r trainingModels, include=FALSE}

sapply(names(formulas), function(fmNo) {
  fm <- formulas[fmNo]
  
  sapply(names(algorithms), function(algorithm) {
    classifier <- get('algorithms')[[algorithm]]
    features <- get('fm')
    fmNo <- get('fmNo')
    for(i in 1:repetitions) {
      set.seed(seed+i*100+1000)
      tt <- manipulations$trainTest(get('db'), p=0.75)
      scaledTt <- manipulations$scaledTrainTest(tt$train, tt$test)
      
      control <- trainControl(method="repeatedcv", number=10, repeats=3,
                              allowParallel = T)
      
      fit <- classifier(scaledTt$train, features[[1]], method=algorithm,
                        trControl=control)
      confMatrix <- confusionMatrix(predict(fit, newdata=scaledTt$test),
                                    scaledTt$test$gfrloss2)
      
      assign("result", rbind(get('result'), data.frame(
        method=paste(algorithm, fmNo),
        Accuracy=confMatrix$overall['Accuracy'],
        AccuracyNull=confMatrix$overall['AccuracyNull'],
        Sensitivity=confMatrix$byClass['Sensitivity'],
        Specificity=confMatrix$byClass['Specificity'],
        Kappa=confMatrix$overall['Kappa']
      )), envir = .GlobalEnv)
      
    }
  })
})

```

```{r printingTables}

result2 <- result[0, ]

c<-sapply(levels(result$method), function(method) {
  result <- get('result')
  x<- lapply(result[result$method == method,], function(x){
    if(! is.numeric(x)) {
      return(x[[1]])
    }
    tTest <- t.test(x)
    sMean <- round(tTest$estimate[[1]],3)
    sError <- round(tTest$estimate[[1]] - tTest$conf.int[1], 3)
    
    c(as.character(paste(sMean, '\u00B1', sError)))
    
  })
  
  levels(x$method) <- levels(result$method)
  x <- data.frame(x, stringsAsFactors=FALSE)
  assign('result2', rbind(get('result2'), x), envir = .GlobalEnv)

})
cat(paste('## Running lda and glm ',repetitions,' times.'))
knitr::kable(result2, row.names = F)


```